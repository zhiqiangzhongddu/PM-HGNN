{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io as sio\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'ACM'\n",
    "num_train = 80\n",
    "adam_lr = 0.01\n",
    "hid_dim = 256\n",
    "drop_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of Model are:\n",
      "data_name ACM\n",
      "num_train 80\n",
      "num_epoch 1001\n",
      "batch_size None\n",
      "adam_lr 0.01\n",
      "l2_regularization 0.0005\n",
      "dropout True\n",
      "drop_ratio 0.5\n",
      "relu True\n",
      "hid_dim 256\n",
      "verbose 1\n",
      "early_stop 100\n",
      "model_dir checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model\n",
      "alias test_model_2020_7_7_21_3\n",
      "use_cuda True\n"
     ]
    }
   ],
   "source": [
    "batch_size = None\n",
    "dropout = True # no necessary\n",
    "relu = True # optional for shallow layers\n",
    "early_stop = 100\n",
    "\n",
    "#################Parameters for model#################\n",
    "loc_time = time.localtime()\n",
    "model_config={'data_name': data_name,\n",
    "              'num_train': num_train,\n",
    "              'num_epoch': 1001, # 2001\n",
    "              'batch_size': batch_size,\n",
    "              'adam_lr': adam_lr, # 1e-2, 5e-3\n",
    "              'l2_regularization': 5e-4, #5e-4, 7e-4\n",
    "              'dropout': dropout, \n",
    "              'drop_ratio': drop_ratio,\n",
    "              'relu': relu,\n",
    "              'hid_dim': hid_dim,\n",
    "              'verbose': 1, \n",
    "              'early_stop': early_stop,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model',\n",
    "              'alias':'test_model_{}_{}_{}_{}_{}'.format(loc_time[0], loc_time[1], loc_time[2], loc_time[3], loc_time[4])}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model_config['use_cuda'] = True\n",
    "else:\n",
    "    model_config['use_cuda'] = False\n",
    "\n",
    "print('Parameters of Model are:')\n",
    "for _ in model_config:\n",
    "    print(_, model_config[_])\n",
    "    \n",
    "# set up device\n",
    "device = torch.device('cuda:'+str(0) if model_config['use_cuda'] else 'cpu')\n",
    "model_config['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('../data/acm/ACM.mat')\n",
    "p_vs_l = data['PvsL']       # paper-field?\n",
    "p_vs_a = data['PvsA']       # paper-author\n",
    "p_vs_p = data['PvsP']       # paper-paper\n",
    "# features\n",
    "p_vs_t = data['PvsT']       # paper-term, bag of words\n",
    "# labels\n",
    "p_vs_c = data['PvsC']       # paper-conference, labels come from that\n",
    "\n",
    "# We assign\n",
    "# (1) KDD papers as class 0 (data mining),\n",
    "# (2) SIGMOD and VLDB papers as class 1 (database),\n",
    "# (3) SIGCOMM and MOBICOMM papers as class 2 (communication)\n",
    "conf_ids = [0, 1, 9, 10, 13]\n",
    "label_ids = [0, 1, 2, 2, 1]\n",
    "\n",
    "p_vs_c_filter = p_vs_c[:, conf_ids]\n",
    "p_selected = (p_vs_c_filter.sum(1) != 0).A1.nonzero()[0]\n",
    "\n",
    "# across levels\n",
    "p_vs_l = p_vs_l[p_selected]\n",
    "p_vs_l = p_vs_l[:, np.where(p_vs_l.sum(0))[1]]\n",
    "# \n",
    "p_vs_a = p_vs_a[p_selected]\n",
    "p_vs_a = p_vs_a[:, np.where(p_vs_a.sum(0))[1]]\n",
    "# \n",
    "a_vs_l = p_vs_a.transpose() * p_vs_l\n",
    "\n",
    "# within level\n",
    "p_vs_p = p_vs_p[p_selected,:][:,p_selected]\n",
    "a_vs_a = p_vs_a.transpose() * p_vs_a\n",
    "l_vs_l = p_vs_l.transpose() * p_vs_l\n",
    "\n",
    "# others\n",
    "p_vs_t = p_vs_t[p_selected]\n",
    "p_vs_c = p_vs_c[p_selected]\n",
    "\n",
    "features = torch.FloatTensor(p_vs_t.toarray())\n",
    "features_author = torch.FloatTensor(np.identity(a_vs_a.shape[0]))\n",
    "features_field = torch.FloatTensor(np.identity(l_vs_l.shape[0]))\n",
    "\n",
    "pc_p, pc_c = p_vs_c.nonzero()\n",
    "labels = np.zeros(len(p_selected), dtype=np.int64)\n",
    "for conf_id, label_id in zip(conf_ids, label_ids):\n",
    "    labels[pc_p[pc_c == conf_id]] = label_id\n",
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('../data/acm/ACM.mat')\n",
    "p_vs_l = data['PvsL']       # paper-field?\n",
    "p_vs_a = data['PvsA']       # paper-author\n",
    "p_vs_t = data['PvsT']       # paper-term, bag of words\n",
    "p_vs_c = data['PvsC']       # paper-conference, labels come from that\n",
    "\n",
    "# We assign\n",
    "# (1) KDD papers as class 0 (data mining),\n",
    "# (2) SIGMOD and VLDB papers as class 1 (database),\n",
    "# (3) SIGCOMM and MOBICOMM papers as class 2 (communication)\n",
    "conf_ids = [0, 1, 9, 10, 13]\n",
    "label_ids = [0, 1, 2, 2, 1]\n",
    "\n",
    "p_vs_c_filter = p_vs_c[:, conf_ids]\n",
    "p_selected = (p_vs_c_filter.sum(1) != 0).A1.nonzero()[0]\n",
    "p_vs_l = p_vs_l[p_selected]\n",
    "p_vs_a = p_vs_a[p_selected]\n",
    "p_vs_t = p_vs_t[p_selected]\n",
    "p_vs_c = p_vs_c[p_selected]\n",
    "\n",
    "pa = dgl.bipartite(p_vs_a, 'paper', 'pa', 'author')\n",
    "ap = dgl.bipartite(p_vs_a.transpose(), 'author', 'ap', 'paper')\n",
    "pl = dgl.bipartite(p_vs_l, 'paper', 'pf', 'field')\n",
    "lp = dgl.bipartite(p_vs_l.transpose(), 'field', 'fp', 'paper')\n",
    "hg = dgl.hetero_from_relations([pa, ap, pl, lp])\n",
    "\n",
    "features = torch.FloatTensor(p_vs_t.toarray())\n",
    "\n",
    "pc_p, pc_c = p_vs_c.nonzero()\n",
    "labels = np.zeros(len(p_selected), dtype=np.int64)\n",
    "for conf_id, label_id in zip(conf_ids, label_ids):\n",
    "    labels[pc_p[pc_c == conf_id]] = label_id\n",
    "labels = torch.LongTensor(labels)\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "float_mask = np.zeros(len(pc_p))\n",
    "for conf_id in conf_ids:\n",
    "    pc_c_mask = (pc_c == conf_id)\n",
    "    float_mask[pc_c_mask] = np.random.permutation(np.linspace(0, 1, pc_c_mask.sum()))\n",
    "train_idx = np.where(float_mask <= 0.2)[0]\n",
    "val_idx = np.where((float_mask > 0.2) & (float_mask <= 0.3))[0]\n",
    "test_idx = np.where(float_mask > 0.3)[0]\n",
    "\n",
    "num_nodes = hg.number_of_nodes('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
